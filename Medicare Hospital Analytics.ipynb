{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Importing all necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import os.path\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import csv\n",
    "import io\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a staging sub directory called 'staging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_dir_name = \"staging\"\n",
    "os.mkdir(staging_dir_name)\n",
    "os.path.isdir(staging_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download zip file from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip\"\n",
    "r = requests.get(url)\n",
    "zip_file_name = os.path.join(staging_dir_name, \"Hospital_Revised_Flatfiles.zip\")\n",
    "zf = open(zip_file_name, \"wb\")\n",
    "zf.write(r.content)\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping the zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile(zip_file_name,\"r\")\n",
    "z.extractall(staging_dir_name)\n",
    "z.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to standardize all the table and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_standardize(name,torc = \"t\"):\n",
    "    name.strip()\n",
    "    name=name.lower()\n",
    "    name=name.replace(\" \",\"_\").replace(\",\",\"_\").replace(\"\\t\",\"_\").replace(\"/\",\"_\").replace(\"-\",\"_\").replace(\"%\",\"pct\").replace(\"#\",\"_num\")\n",
    "    if torc == 't':\n",
    "        if not name[0].isalpha():\n",
    "            name=\"t_\"+name\n",
    "    if torc == 'c':\n",
    "        if not name[0].isalpha():\n",
    "            name=\"c_\"+name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "staging_path = wd + '//staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding all the files to utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(staging_path)\n",
    "files = os.listdir()\n",
    "for file in files:\n",
    "    if not file.endswith(\".csv\"):\n",
    "        os.remove(file)\n",
    "        continue\n",
    "    base_file = file + \"-base\"\n",
    "    os.rename(file,base_file)\n",
    "    new_name=name_standardize(file,\"t\")\n",
    "    with io.open(base_file, 'r', encoding='cp1252') as f_in:\n",
    "        f_in = csv.reader(x.replace('\\0', '') for x in f_in)\n",
    "        with io.open(new_name, 'w', encoding=\"utf8\", newline='') as f_out:\n",
    "            f_out = csv.writer(f_out,delimiter=',')\n",
    "            for i, line in enumerate(f_in):\n",
    "                if line == [] or line == [' ']:\n",
    "                    continue\n",
    "                elif i == 0:\n",
    "                    s = []\n",
    "                    for x in range(0,len(line)):\n",
    "                        s.append(name_standardize(line[x],\"c\"))\n",
    "                    f_out.writerow([str(elem) for elem in s])\n",
    "                else:\n",
    "                    f_out.writerow([str(elem) for elem in line])\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a database 'medicare_hospital_compare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = sqlite3.connect('medicare_hospital_compare.db')\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tables in the database and inserting data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(staging_path)\n",
    "tablenames = os.listdir()\n",
    "for table in tablenames:\n",
    "    if table.endswith(\".csv-base\"):\n",
    "        continue\n",
    "    else:\n",
    "        tablename = table.rstrip('.csv')\n",
    "        with io.open(table, 'r', encoding=\"utf8\") as t_in:\n",
    "            table_in = csv.reader(t_in)\n",
    "            r = next(table_in)\n",
    "            header = []\n",
    "            for i in range(0,len(r)):\n",
    "                header.append(r[i] + ' ' + 'TEXT')\n",
    "                cols = ','.join(header)\n",
    "            sql ='CREATE TABLE IF NOT EXISTS ' + tablename + ' (' + cols + ')'\n",
    "            c.execute(sql)\n",
    "            insert_stmt = \"INSERT INTO \" + tablename + '({0})' + ' VALUES({1});'\n",
    "            query = insert_stmt.format(','.join(r), ','.join('?' * len(r)))\n",
    "            for line in table_in:\n",
    "                c.execute(query, line)\n",
    "os.chdir(wd)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading hospital_ranking_focus_states excel from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\"\n",
    "r = requests.get(url)\n",
    "with open('ranking.xlsx', 'wb') as output:\n",
    "    output.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting hospital_ranking_focus_states file to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile(\"ranking.xlsx\")\n",
    "\n",
    "db = sqlite3.connect('medicare_hospital_compare.db')\n",
    "c = db.cursor()\n",
    "file = xl.sheet_names\n",
    "\n",
    "for sheet in file:\n",
    "    data = pd.DataFrame()\n",
    "    header = []\n",
    "    n_t = name_standardize(sheet)\n",
    "    data = pd.read_excel(xl,sheetname=sheet, dtype=str) \n",
    "    h = list(data.columns.values)\n",
    "    for value in h:\n",
    "        header.append(name_standardize(value,\"c\"))\n",
    "    data.columns = header\n",
    "    data.applymap(str)\n",
    "    data.to_sql(n_t, db, if_exists=\"replace\",index=False)\n",
    "\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating tables in database for getting required information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Connection.commit>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = sqlite3.connect('medicare_hospital_compare.db')\n",
    "c = db.cursor()\n",
    "\n",
    "c.execute('drop table if exists newtable')\n",
    "c.execute('create table newtable as select b.ranking, a.provider_id, a.hospital_name, a.city, a.state, a.county_name from hospital_general_information a join hospital_national_ranking b on a.provider_id = b.provider_id')\n",
    "c.execute('drop table if exists final_table')\n",
    "c.execute('create table final_table AS select b.*, a.state_name FROM focus_states a join newtable b on b.state = a.state_abbreviation')\n",
    "db.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating databases from all these newly created table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "national_df = pd.read_sql_query(\"select * from newtable;\", db)\n",
    "final_df = pd.read_sql_query(\"select * from final_table;\", db)\n",
    "measure_df = pd.read_sql_query(\"select state, measure_id, measure_name, score from timely_and_effective_care___hospital\", db)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the information of all the required columns into a new excel file named hospital_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states= list(final_df.state_name.unique())\n",
    "abriv= list(final_df.state.unique())\n",
    "state_dict = dict(zip(abriv, states))\n",
    "final_df[['ranking']] = final_df[['ranking']].astype(int)\n",
    "national_df[['ranking']] = national_df[['ranking']].astype(int)\n",
    "title = ['Provider ID','Hospital Name','City','State','County']\n",
    "\n",
    "writer = pd.ExcelWriter('hospital_ranking.xlsx')\n",
    "\n",
    "Nationwide = national_df.sort_values('ranking')\n",
    "Nationwide = Nationwide.head(n=100)\n",
    "del Nationwide['ranking']\n",
    "Nationwide.columns = title\n",
    "Nationwide.to_excel(writer,'Nationwide',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for state in states:\n",
    "    temp = final_df[final_df['state_name'] == state]\n",
    "    d[state] = temp.sort_values('ranking')\n",
    "    d[state] = d[state].head(n=100)\n",
    "    del d[state]['state_name']\n",
    "    del d[state]['ranking']\n",
    "    d[state].columns = title\n",
    "    d[state].to_excel(writer,state,index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the summary statistics like min, max, average and standard deviation from the data and writing it to measure_statistics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "measures = measure_df[measure_df['score'].astype(str).str.isdigit()]\n",
    "measures['score'] = measures['score'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "writer2 = pd.ExcelWriter('measure_statistics.xlsx')\n",
    "nation_stat =  measures.groupby(['measure_id','measure_name'])\n",
    "summary_statistics = nation_stat['score'].describe()\n",
    "del summary_statistics['count']\n",
    "del summary_statistics['25%']\n",
    "del summary_statistics['50%']\n",
    "del summary_statistics['75%']\n",
    "summary_statistics = summary_statistics[['min','max','mean','std']]\n",
    "summary_statistics['std'].fillna(0, inplace=True)\n",
    "summary_statistics=summary_statistics.reset_index()\n",
    "col_name = ['Measure ID','Measure Name','Minimum','Maximum','Average','Standard Deviation']\n",
    "summary_statistics.columns = col_name\n",
    "summary_statistics.to_excel(writer2,'Nationwide',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the data by states and finding statistics for each individual state and writing it into different excel sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_data = measures.groupby(['state', 'measure_id','measure_name'])\n",
    "state_summary = grouped_data['score'].describe()\n",
    "del state_summary['count']\n",
    "del state_summary['25%']\n",
    "del state_summary['50%']\n",
    "del state_summary['75%']\n",
    "state_summary = state_summary[['min','max','mean','std']]\n",
    "state_summary['std'].fillna(0, inplace=True)\n",
    "state_summary=state_summary.reset_index()\n",
    "col_name = ['state', 'Measure ID','Measure Name','Minimum','Maximum','Average','Standard Deviation']\n",
    "state_summary.columns = col_name\n",
    "\n",
    "for a,f in state_dict.items():\n",
    "    temp = state_summary[state_summary['state'] == a]\n",
    "    del temp['state']\n",
    "    temp.to_excel(writer2,f,index=False)\n",
    "writer2.save()\n",
    "writer2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
